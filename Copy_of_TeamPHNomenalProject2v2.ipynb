{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "566fb298a40d4a4c85f44715fdcff90f",
      "8a29ca1aeedc46459548701acd449a9a",
      "91f1152e66734d32ac453468471d793a",
      "cfef9b25d75048948647ac61096c767f",
      "d33a5f3041ba4da1bdb4c4b6b5ee11b1",
      "85be462a3e7e4ba18aca6148bb74168f",
      "5cbf5bcc1fb048089a4bf3ab2d9443cc",
      "f0b383e3211d4b4fa1eab8257238eb9b",
      "045ac6ef5d1d4cbaad64e9daf567c0e4",
      "d07a20fbd5d046f1a9865b108ca695af",
      "7ae1ddab0fdd4d2e8b918786d4006767",
      "c93dcdf3b0ed4b11aebb549fec0c1413",
      "2edfb94009ec4bd4ba798ae41036287f",
      "1334a4ebdb714483bd5bc32aef90c19f",
      "7d3bdeb204364b5ba5bed4b6943ac5a5",
      "eb2005e994e14e8cb0e68962ab314ddf",
      "c65e3078be68428bb92de972417def37",
      "57c7d6b110614e448add7e3281bd8932",
      "c2132108c1134ac69f4d75f4abbc0537",
      "9b2fa5013ddf44869067b3741a9c5e5f",
      "6f0286c3401543e1b5cf7508c669c35f",
      "f958c60ebfea4f948f920baac803f1b3",
      "e586e39b6fee4852966f1d4e8d42aec9",
      "ae8c81d98efd408584e88b2c8c98d1b3",
      "c1409e4b940841dda7382aa0239570cd",
      "322fe56eb6e14318ad8036eaebb348fc",
      "d2052bba538f42d9a7dcff9c02a13c5e",
      "14584512ce9b4b32996b4eda7a49a2b8",
      "c45e7b93d892436b99e7819c09ab637c"
     ]
    },
    "id": "b2RYz4BYI1HN",
    "outputId": "435368e4-fb78-407b-a70d-bd4651bb3d1a"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
    "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
    "import kagglehub\n",
    "kagglehub.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVGXQAG8ZyBI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "p5wzVaRLI1HQ",
    "outputId": "8eb8955a-0a39-4a7e-f920-c35368e18925"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "deep_learning_spring_2025_project_2_path = kagglehub.competition_download('deep-learning-spring-2025-project-2')\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "9CkkZVIwI1HR"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Ibwlyy8NLI05",
    "outputId": "ac80e274-fa2b-4ea2-b255-5f8caae4cd61"
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers\n",
    "!pip install datasets\n",
    "!pip install peft\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523,
     "referenced_widgets": [
      "c0fc6d72c6194e7488da86f10c9ed9f8",
      "11f0c38f6e604395a0f60cee0ea659f6",
      "d8056e1bc09d47e9ba1de5970d4d750e",
      "25760f956e0c4fa586aaa65d73c9fe77",
      "262e576e2b4b49bcaddd8108583cb913",
      "16872dd51d9d4ccc829ab1751f96ba87",
      "6b22408c2f424e89a7c457d8ffd68618",
      "15309a52fd5e42b8b9d0136ad98f632d",
      "f7e8b6532ec345c69c475477d572e820",
      "b531ad50f79c48eaa060e8e099b0c6ef",
      "85c23ba87b7c48f9bf1b86f84f03d72f",
      "ae7d9078a7e04dac86dfd914d85886b3",
      "994be0bc6e8842f999179c485ebae58c",
      "dd2991dd38c44aa288c50398ffd630ca",
      "fe0c37247882497c894ef2ac8e60df1d",
      "c22be734847d46558867e136e5375776",
      "9e9894e9bafd40d49dd0b743776a0374",
      "85efc5e82d1642309f22d42dddfbe944",
      "111891a2ab9f4e43ad735e908ad3ed98",
      "987fc67c8db0481584c929ac7f355a5c",
      "b4066d8cab6144f1ae12df244ae3c5fd",
      "645de06d03304f7eabe09a3368380b1b",
      "9b3851248ee14512badaa6bff72e41f7",
      "6dfd3512663d455a8b294f508b94866c",
      "1ccf54a35db8462bb96ed77db7bd34d9",
      "19c088379a514d02ac49b3b551de6dac",
      "de2aebb4f005447f9908cba18c78de9e",
      "162ceceefa93466e901b9c08460d6f05",
      "57d9a6b2627243c9905b31a7609208ad",
      "e8494fccc4aa486096ed7084a66060c5",
      "3aa76fb1ef5e4050a7d429b3c1e9acee",
      "e145ab399e834db18988992a2b3cdc2b",
      "d98401ef2591445d8c9c1893e63f167e",
      "39b62273990a4c5d8a174ab176127f7a",
      "5f839dae8d6d4a1aa54e6de1f3201845",
      "60f3d011fb05484f89abb03cdd49886e",
      "d46bf5e6ce914e6b8cb5936790f1c876",
      "5647963551ea40e0a2414afb7f67a343",
      "59994218ad4747ec8a30284a7cbd4878",
      "c1d8a3f29a9146ad90e1c2bbd8e2956c",
      "48809a38d619423c84e915ea3bb0eae5",
      "fd16e4f5ae734adfb792d5f11c73476d",
      "2bf80c98953a4cbfad2a53310d6da49f",
      "10a4de3222d24d91b7442b3bcf6e7ba2",
      "79110f275e0048a0980d5c7bc142a802",
      "ea1f075523c94decbdb34a2f3227d7fb",
      "693e61c1f03f435b82679fbba495127a",
      "5e46a3b6ba3341f984d317b4e8c071dd",
      "63f23d97b347464da6638425ab5be1b4",
      "f49836badc5f4f90bcffef2865d38a7a",
      "5978790d8617474b908741fa3e5724bf",
      "6386605bd8894b3cb1392b0dfbb29ec2",
      "b8d782e51b364868808c656a14f281b0",
      "fd697bb49e4c466fb13d3e2b1b6efcb9",
      "de6b3f954e8c4224b833384888b8de24",
      "512471d80e5b4f689cc866f308eeb460",
      "8e4751c716b54897a93dfbe92788e644",
      "e69e3a9a613040b9bbd58bbe48617478",
      "622c3b55911f4026b0e0c7066266f541",
      "326380a3e7e54584ade8d0b4af64c2c0",
      "a708ae252bc3485a8b15366f4b5fa87d",
      "417ade9d7e124c40ba7e765d579183da",
      "93c5174c5f884c4eb6c9fb747a986ae3",
      "5f4db283f9974d8380a1a3ddd8358689",
      "4cc155071ad548cd8d44fe4fd56c5555",
      "ff97ca7b4dfa41e28a4dd02910282df6",
      "f347312bfc114ea9aece3a1a5bc6e55a",
      "c0d628db3533444badf49cd691ed90e2",
      "c2ddea2706c0457e87ebba79dafed644",
      "94dce0696cbf47a4868fbf76f891e038",
      "99b461e557bb4cb79611a7bec3903394",
      "41d4eb3c59bf47e5a3931cb53645accb",
      "a958c90608b042fc9b62bae476e6aa72",
      "f7861a022d5442958ce86a28017fd772",
      "8ad88f76b47847f0bd870c3f638e90d0",
      "d69f44b58247433caa80eed4ef10c9fe",
      "9c502584ccba44f2b4940c3b87690047",
      "1768d02e827245a5acd72d94305dd45d",
      "3f5b58ef68c34f368ad222ca1209cc1d",
      "b4c120fe34b744588a99f0d6b83bbb6b",
      "c9caccab29444034ab9df9a010f9e300",
      "20ef4b5feebf494d8b8e1403a5823caa",
      "4cec5efc5dff4122b351748d654b4026",
      "0dfd21529a524bd7ae204ba4d0d048b1",
      "d5282ac5085843c38e7e0ee82763d509",
      "fbb7fad0053141268ce1077a590d5fc7",
      "e33788d54d7748dc839742bdc2f03018",
      "5cb7655443414818909468da7a9efba7",
      "11775128fa4e408f978daea9b81f04dc",
      "60a4811eea52406b9122b354f43c5509",
      "cc80e7e2e46840f0b9af909ee120c386",
      "cec3f0c5ec874a4cb7f47be05d4ead6a",
      "1299a89706c3411180fb0776bfee9ad7",
      "9310e6e474d04ad4b757d713687bace8",
      "8e49a7f9f8e445458f99adee2ccf71e0",
      "27dd9ace573642d9aa0d0435505c9577",
      "752be018ee054900b72c3587e72664e5",
      "75e54bcb16d445cf9bf6ac09dc4a3d79",
      "9217b5b4659847ee8cfd0a5bb974d469",
      "7ec1c5a1d2ad48b98961946200c115e7",
      "f78992d56bd44484b05a60de1b5b426e",
      "0c3e46b111a84b1294fb27bfffaa2481",
      "b1d8d1954a694dd28e55e83e76fc1e61",
      "ccf1f9bced644e54808dfe2952849e30",
      "f7a81a6293264d87bba498726dc6c524",
      "c26c099e0188425f9d012a158110e275",
      "a426f350b39c4f179c7ff0d3950d68fe",
      "36c2aeb6a5754b26aedc408650775a95",
      "beaf0675dbe548a59a9b1b40e1e3b3bf",
      "57ef1156909f444a9277df31ca03275a",
      "63638f014f594d21b72775467e09b0a6",
      "073b2b4b716e430daad982afb16ef9c0",
      "a1ad584cd5eb45479decd169b8b8a0a9",
      "cb188d81d23043169f7107100c1fcfc2",
      "0803ab129272451182b6cded119d23b0",
      "7f8047148bc7409a9e37bb32db4a39bc",
      "c94a547a496d42fabd3fd488bc7a6478",
      "24ec8c56d5914a21941f9d365ad99d01",
      "2cbfd2d21be140f48ccfb46810a69bc8",
      "729964d22b57439289a87791955d57bc",
      "ed24b542e2e94e5da16589b751c9d473",
      "5945e13f62d44e1798684698fe84f6d7",
      "474dcc0447e2476cb78123f95fd07d8d",
      "8963a704da06491488c4ded02d18b1a4",
      "53025338e1384e8c8a2ff87c165580ae",
      "f2304194138c4e4c95215e3a87734f0d",
      "7696ed92eeb44caf856e4e59572e0d6a",
      "462cedc8ccf54c53904fcddd68c6199b",
      "b2305f741d8a4d39bbf8da738abd99ca",
      "2eabcec27d66411aa30407e93b0514ce",
      "3a3a22c304e34289ba57d948d0054503",
      "9563143e12a240bba3f62fcf1d069327"
     ]
    },
    "id": "m9BsfoXYI1HS",
    "outputId": "a3023f66-a077-4bd1-88bc-3df875d50e6b"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Import libraries\n",
    "# -----------------------------\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Use GPU if available\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Load and preprocess AGNEWS dataset\n",
    "# -----------------------------\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "571c24c2fb8d464f878bc4b4c1a3990a",
      "70101c83b278460c9bf13a39a8b850d7",
      "bede34e083524af597af505d40f69a17",
      "9670366643c64633af51fcea92d3c742",
      "2da6cd759741459d8f5c5447ba059f95",
      "ca1482fbdb40438ba05b832ae34c9b2f",
      "2ca3812dc28e4936a1b887dda92cc413",
      "32327dd8280f44519e0254ed25e43f97",
      "ac569e1e02b84cdaabe68ec7f231abe2",
      "fbc8ec112c694214aceda07fc19d3f84",
      "4d66c2a664de44c69f7fdb31c01b261c"
     ]
    },
    "id": "aSxz43eRI1HS",
    "outputId": "d9bf6932-a1fc-4593-a783-e6ffbb68d7cf"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4. Load RoBERTa model with LoRA adapters\n",
    "# -----------------------------\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=4)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.to(device)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Oo0cZJiCNjVN",
    "outputId": "3331d00b-062b-4a53-e606-909de074669c"
   },
   "outputs": [],
   "source": [
    "print(TrainingArguments.__module__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAnTPzDbI1HS"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5. Define training arguments\n",
    "# -----------------------------\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim=\"adamw_torch\",\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cZdn9C3I1HT"
   },
   "outputs": [],
   "source": [
    "def get_trainer(model):\n",
    "    return  Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2475
    },
    "id": "JdLRjp_iI1HT",
    "outputId": "ede59cf9-fd94-404e-c643-8486c99add54"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 6. Train the model with Hyperparameter sweep\n",
    "# -----------------------------\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import pandas as pd\n",
    "\n",
    "EXPERIMENT = True  # True to sweep, False for default single run\n",
    "\n",
    "results = []\n",
    "trained_trainers = {}\n",
    "\n",
    "grid = [(r, alpha)\n",
    "        for r in [1, 2, 3, 4, 5]\n",
    "        for alpha in [4, 8, 16, 32]]\n",
    "\n",
    "if EXPERIMENT:\n",
    "    # 1) Filter valid configs\n",
    "    valid_configs = []\n",
    "    for r, alpha in grid:\n",
    "        cfg = LoraConfig(\n",
    "            r=r,\n",
    "            lora_alpha=alpha,\n",
    "            lora_dropout=0.1,\n",
    "            bias=\"none\",\n",
    "            target_modules=[\"query\",\"key\",\"value\",\"dense\"],\n",
    "            task_type=TaskType.SEQ_CLS,\n",
    "        )\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=4)\n",
    "        model = get_peft_model(model, cfg)  # wrap into `model`\n",
    "        trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        if trainable <= 1_000_000:\n",
    "            valid_configs.append((r, alpha))\n",
    "\n",
    "    # 2) Train & evaluate each valid config\n",
    "    for r, alpha in valid_configs:\n",
    "        print(f\"→ Training r={r}, α={alpha}\")\n",
    "        cfg = LoraConfig(\n",
    "            r=r,\n",
    "            lora_alpha=alpha,\n",
    "            lora_dropout=0.1,\n",
    "            bias=\"none\",\n",
    "            target_modules=[\"query\",\"key\",\"value\",\"dense\"],\n",
    "            task_type=TaskType.SEQ_CLS,\n",
    "        )\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=4)\n",
    "        model = get_peft_model(model, cfg)  # assign to `model`\n",
    "        model.print_trainable_parameters()\n",
    "\n",
    "        trainer = get_trainer(model)\n",
    "        trainer.train()\n",
    "        metrics = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "        acc = metrics[\"eval_accuracy\"]\n",
    "\n",
    "        results.append({\n",
    "            \"r\": r,\n",
    "            \"alpha\": alpha,\n",
    "            \"trainable_params\": sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "            \"accuracy\": acc,\n",
    "        })\n",
    "        trained_trainers[(r, alpha)] = trainer\n",
    "\n",
    "    # 3) Aggregate & pick best\n",
    "    df = pd.DataFrame(results).sort_values(\"accuracy\", ascending=False).reset_index(drop=True)\n",
    "    best_r, best_alpha = int(df.loc[0, \"r\"]), int(df.loc[0, \"alpha\"])\n",
    "    best_trainer = trained_trainers[(best_r, best_alpha)]\n",
    "    model = best_trainer.model  # final `model`\n",
    "\n",
    "else:\n",
    "    # Default single run: r=1, alpha=32\n",
    "    best_r, best_alpha = 1, 32\n",
    "    cfg = LoraConfig(\n",
    "        r=best_r,\n",
    "        lora_alpha=best_alpha,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"query\",\"key\",\"value\",\"dense\"],\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "    )\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=4)\n",
    "    model = get_peft_model(model, cfg)\n",
    "    print(\"Default run parameters:\")\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    trainer = get_trainer(model)\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "    acc = metrics[\"eval_accuracy\"]\n",
    "\n",
    "    results = [{\n",
    "        \"r\": best_r,\n",
    "        \"alpha\": best_alpha,\n",
    "        \"trainable_params\": sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "        \"accuracy\": acc,\n",
    "    }]\n",
    "    df = pd.DataFrame(results)\n",
    "    best_trainer = trainer\n",
    "\n",
    "# 4) Summary\n",
    "print(\"Sweep/Default results:\")\n",
    "print(df)\n",
    "print(f\"\\nSelected best → r={best_r}, α={best_alpha}, acc={df.loc[0,'accuracy']:.4f}\")\n",
    "# `model` and `best_trainer` now hold your final LoRA‑adapted, trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "8UTNFuwCI1HU",
    "outputId": "8736d867-7c40-4e83-81b7-9e6b0ae62c74"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 6.2 Visualization\n",
    "# -----------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = best_trainer.state.log_history\n",
    "\n",
    "train_entries = [\n",
    "    e for e in history\n",
    "    if \"loss\" in e and \"eval_loss\" not in e\n",
    "]\n",
    "train_steps = [e[\"step\"] for e in train_entries if \"step\" in e]\n",
    "train_loss  = [e[\"loss\"] for e in train_entries]\n",
    "\n",
    "eval_entries = [e for e in history if \"eval_loss\" in e]\n",
    "eval_steps = [e[\"step\"] for e in eval_entries]\n",
    "eval_loss  = [e[\"eval_loss\"] for e in eval_entries]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_steps, train_loss, label=\"train_loss\")\n",
    "plt.plot(eval_steps,  eval_loss,  label=\"eval_loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs. Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "pivot = df.pivot(index=\"r\", columns=\"alpha\", values=\"accuracy\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(pivot, aspect=\"auto\")\n",
    "plt.xticks(range(len(pivot.columns)), pivot.columns)\n",
    "plt.yticks(range(len(pivot.index)),   pivot.index)\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"r\")\n",
    "plt.title(\"Sweep Accuracy Heatmap\")\n",
    "plt.colorbar(label=\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "BoZtXxpAI1HU",
    "outputId": "60745aba-6d6d-4ac4-f81e-316324e41b97"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 7. Evaluate the model\n",
    "# -----------------------------\n",
    "eval_results = best_trainer.evaluate()\n",
    "print(\"Final Evaluation Accuracy:\", eval_results[\"eval_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "pWJgOEYlI1HU",
    "outputId": "cd6ff311-f720-4a37-eacd-3d15c7c7e133"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 8. Check trainable parameter count\n",
    "# -----------------------------\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "684fa56af4974ec6ab372b7d80042a22",
      "809f066e923141a1a32400e7ebf8ba0c",
      "e2d18c3de93140ef9a865924fdb6fd17",
      "b2bf57b6f5f544e091d3b0e44bac5783",
      "6f3e5c832a014b41bbe8662e6ab9f95c",
      "0c963732038040a8aad9cd48336ac96d",
      "3c188c6d5e634f6ba921e573b5517c66",
      "3146f9bdbf0e4ebdb2db7f703874a283",
      "9f2033cf8fa34466b6676b65bcdc203f",
      "163840618ecb4d709a5b1e10cca7d6cb",
      "d24257c8e2374864a3e310923b2be463"
     ]
    },
    "id": "nOYEZzCEI1HU",
    "outputId": "34a2aa37-deb1-434e-c2e8-72aa52dc541d"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pickle_path = os.path.join(\n",
    "    deep_learning_spring_2025_project_2_path,\n",
    "    'test_unlabelled.pkl'\n",
    ")\n",
    "# Load dataset object\n",
    "with open(pickle_path, \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "# Convert to HuggingFace Dataset (already is, but this helps formatting)\n",
    "test_dataset = Dataset.from_dict({\"text\": test_dataset[\"text\"]})\n",
    "\n",
    "# Tokenize function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# Apply tokenizer\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "# Create PyTorch DataLoader for batching\n",
    "test_dataloader = DataLoader(tokenized_test_dataset, batch_size=64)\n",
    "\n",
    "# Prediction loop\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        preds = torch.argmax(outputs.logits, dim=-1)\n",
    "        all_predictions.extend(preds.cpu().numpy())\n",
    "print(\"First 10 predictions:\", all_predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "UixLA_ySI1HV",
    "outputId": "a5dfc68c-8ea3-48c0-ad47-2657af3cd7c0"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 10. Save predictions to CSV\n",
    "# -----------------------------\n",
    "df = pd.DataFrame({\n",
    "    \"ID\": list(range(len(all_predictions))),   # ID ✅\n",
    "    \"label\": all_predictions\n",
    "})\n",
    "df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ Batched predictions complete. Saved to submission.csv.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11711500,
     "sourceId": 98084,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
